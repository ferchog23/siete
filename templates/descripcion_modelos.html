<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Descripci√≥n de modelos / Model Description</title>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <style>
    body {
      background-size: cover;
      background-repeat: no-repeat;
      background-position: center;
      transition: background-image 1s ease-in-out;
    }
    .confusion-img {
      max-width: 100%;
      border-radius: 8px;
      border: 1px solid #ccc;
      margin: 10px 0;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 20px;
    }
    table, th, td {
      border: 1px solid #ccc;
    }
    th, td {
      padding: 8px;
      text-align: center;
    }
  </style>
</head>
<body>
  <div class="logos-row" style="background-color: rgba(255, 255, 255, 0.7); border-radius: 10px;">
    <img src="https://agroconciencia.agrosavia.co/media/4finmqqk/unal.png">
    <img src="https://agroconciencia.agrosavia.co/media/pwvhl3sj/fac-ciencias.png">
  </div>

  <div class="container-fluid">
    <h1>Descripci√≥n de los modelos / Model Description</h1>
    <p>Los modelos fueron entrenados con im√°genes de hojas de arveja <em>(Pisum sativum)</em> variedad Vizcaya. / Models were trained using pea leaves (var. Vizcaya).</p>

    <h2>üì± MobileNetV2</h2>
    <p>MobileNetV2 es una arquitectura de redes neuronales convolucionales liviana desarrollada para dispositivos m√≥viles y de baja capacidad computacional (Sandler et al., 2018). Utiliza bloques residuales invertidos y convoluciones separables en profundidad, lo que permite reducir significativamente los par√°metros sin sacrificar mucho el rendimiento. En este experimento obtuvo un <strong>accuracy general de 0.68</strong> y un <strong>macro F1-score de 0.65</strong>, destac√°ndose en la clasificaci√≥n de clases extremas como hojas completamente sanas o completamente infectadas. Su rapidez y eficiencia la hacen ideal para aplicaciones m√≥viles, aunque puede ser menos precisa cuando las clases son visualmente similares.</p>
    <img src="https://i.postimg.cc/Y0FWNN7R/Mobile-Net-V2.png" alt="Matriz de confusi√≥n MobileNet" class="confusion-img">
    <table>
      <thead>
        <tr><th>Clase</th><th>Precisi√≥n</th><th>Recall</th><th>F1-score</th><th>Soporte</th></tr>
      </thead>
      <tbody>
        <tr><td>clase0</td><td>1.00</td><td>1.00</td><td>1.00</td><td>5</td></tr>
        <tr><td>clase1</td><td>0.50</td><td>0.80</td><td>0.62</td><td>5</td></tr>
        <tr><td>clase2</td><td>0.50</td><td>0.20</td><td>0.29</td><td>5</td></tr>
        <tr><td>clase3</td><td>1.00</td><td>0.40</td><td>0.57</td><td>5</td></tr>
        <tr><td>clase4</td><td>0.62</td><td>1.00</td><td>0.77</td><td>5</td></tr>
      </tbody>
    </table>

    <h2>üß† Xception</h2>
    <p>Xception es una arquitectura profunda propuesta por Chollet (2017), basada enteramente en convoluciones separables en profundidad con bloques residuales, lo que le permite aprender representaciones m√°s abstractas. Aunque su capacidad de modelado es mayor, tambi√©n puede ser m√°s sensible al sobreajuste si no se cuenta con un conjunto de datos amplio. En este estudio alcanz√≥ un <strong>accuracy de 0.52</strong> y un <strong>macro F1-score de 0.49</strong>, con alta precisi√≥n en clases espec√≠ficas como clase2 y clase4, pero con desempe√±o bajo en clases intermedias.</p>
    <img src="https://i.postimg.cc/4xQpF19F/exeption.png" alt="Matriz de confusi√≥n Xception" class="confusion-img">
    <table>
      <thead>
        <tr><th>Clase</th><th>Precisi√≥n</th><th>Recall</th><th>F1-score</th><th>Soporte</th></tr>
      </thead>
      <tbody>
        <tr><td>clase0</td><td>0.36</td><td>1.00</td><td>0.53</td><td>5</td></tr>
        <tr><td>clase1</td><td>0.50</td><td>0.20</td><td>0.29</td><td>5</td></tr>
        <tr><td>clase2</td><td>1.00</td><td>0.40</td><td>0.57</td><td>5</td></tr>
        <tr><td>clase3</td><td>0.50</td><td>0.20</td><td>0.29</td><td>5</td></tr>
        <tr><td>clase4</td><td>0.80</td><td>0.80</td><td>0.80</td><td>5</td></tr>
      </tbody>
    </table>

    <h2>üìä Comparaci√≥n de F1-score por clase</h2>
    <div id="grafica"></div>
    <script>
      var data = [
        {
          x: ['clase0', 'clase1', 'clase2', 'clase3', 'clase4'],
          y: [1.00, 0.62, 0.29, 0.57, 0.77],
          name: 'MobileNetV2',
          type: 'bar'
        },
        {
          x: ['clase0', 'clase1', 'clase2', 'clase3', 'clase4'],
          y: [0.53, 0.29, 0.57, 0.29, 0.80],
          name: 'Xception',
          type: 'bar'
        }
      ];
      var layout = {
        title: 'F1-score por clase / F1-score per class',
        barmode: 'group',
        xaxis: { title: 'Clase / Class' },
        yaxis: { title: 'F1-score' }
      };
      Plotly.newPlot('grafica', data, layout);
    </script>

    <h2>üìã Comparaci√≥n resumen entre modelos</h2>
    <table>
      <thead>
        <tr>
          <th>M√©trica</th>
          <th>MobileNetV2</th>
          <th>Xception</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>Accuracy</td><td><strong>0.68</strong></td><td>0.52</td></tr>
        <tr><td>F1-score macro</td><td>0.65</td><td><strong>0.49</strong></td></tr>
        <tr><td>Mejores clases</td><td>0 (sana), 4 (severa)</td><td>2 (intermedia), 4 (severa)</td></tr>
        <tr><td>Inferencia</td><td>R√°pida y eficiente</td><td>Ligeramente m√°s costosa</td></tr>
        <tr><td>Requisitos</td><td>Bajo consumo de recursos</td><td>M√°s demandante computacionalmente</td></tr>
      </tbody>
    </table>

    <h3>üìö Referencias</h3>
    <ul>
      <li>Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., & Chen, L. C. (2018). <em>MobileNetV2: Inverted Residuals and Linear Bottlenecks</em>. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 4510‚Äì4520. https://doi.org/10.1109/CVPR.2018.00474</li>
      <li>Chollet, F. (2017). <em>Xception: Deep Learning with Depthwise Separable Convolutions</em>. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1251‚Äì1258. https://doi.org/10.1109/CVPR.2017.195</li>
    </ul>

    <p>
      <a href="/otro-modelo">üîß Probar otro modelo / Try another model</a> |
      <a href="/">‚¨ÖÔ∏è Volver inicio / Back home</a>
    </p>
  </div>

  <script>
    const imagenesFondo = [
      'https://i.postimg.cc/sgmp0XJs/DJI-0246-scaled.jpg',
      'https://i.postimg.cc/Nf49Qn2x/DJI-0225-scaled.jpg',
      'https://i.postimg.cc/fTwyqvqS/DSC04009-scaled.jpg'
    ];
    let fondoActual = 0;
    function rotarFondo() {
      document.body.style.backgroundImage = `url('${imagenesFondo[fondoActual]}')`;
      fondoActual = (fondoActual + 1) % imagenesFondo.length;
    }
    setInterval(rotarFondo, 7000);
    window.onload = rotarFondo;
  </script>
</body>
</html>
